# ğŸš€ PLAN DE MODERNIZACIÃ“N REFINADO - AI SERVICE
## Para Synology DSM 420+ (10GB RAM) con Builds Externalizados

## ğŸ“‹ RESUMEN EJECUTIVO

Este documento adapta el plan de modernizaciÃ³n considerando las limitaciones del hardware Synology DSM 420+ y aprovecha servicios externos para builds y CI/CD, manteniendo solo el runtime en el NAS.

### ğŸ¯ Objetivos Adaptados

1. **Externalizar builds pesados** - GitHub Actions para CI/CD
2. **Runtime optimizado** - Solo contenedores ligeros en el NAS
3. **GestiÃ³n eficiente de recursos** - MÃ¡ximo 8GB RAM para servicios
4. **Rollback local rÃ¡pido** - Usando Docker tags locales
5. **Observabilidad ligera** - MÃ©tricas esenciales sin overhead

## ğŸ—ï¸ ARQUITECTURA HÃBRIDA PROPUESTA

### âœ… DivisiÃ³n de Responsabilidades

```
EXTERNOS (GitHub/Cloud):
- Build de imÃ¡genes
- EjecuciÃ³n de tests
- Security scanning
- Push a registry
- AnÃ¡lisis de cÃ³digo

NAS (Runtime Only):
- Pull de imÃ¡genes
- EjecuciÃ³n de contenedores
- Base de datos PostgreSQL
- Logs locales
- Backups automÃ¡ticos
```

### ğŸ“ FLUJO DE DEPLOYMENT OPTIMIZADO

```
Developer â†’ GitHub â†’ GitHub Actions â†’ Docker Hub â†’ NAS Pull â†’ Deploy
                          â†“
                    Tests + Build
                          â†“
                    Security Scan
```

## ğŸ”§ CONFIGURACIÃ“N ESPECÃFICA PARA NAS

### 1. ESTRUCTURA SIMPLIFICADA

```
ai-service/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ build-and-test.yml    # Build externo
â”‚       â””â”€â”€ notify-deploy.yml      # Notifica al NAS
â”œâ”€â”€ deploy/
â”‚   â”œâ”€â”€ nas/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml    # Runtime config
â”‚   â”‚   â”œâ”€â”€ .env.template         # Variables
â”‚   â”‚   â””â”€â”€ update.sh             # Script pull & deploy
â”‚   â””â”€â”€ backup/
â”‚       â””â”€â”€ backup-strategy.sh    # Backup automÃ¡tico
â”œâ”€â”€ monitoring/
â”‚   â””â”€â”€ lightweight/
â”‚       â”œâ”€â”€ health-check.sh       # Checks bÃ¡sicos
â”‚       â””â”€â”€ metrics-exporter.sh   # MÃ©tricas mÃ­nimas
â””â”€â”€ scripts/
    â””â”€â”€ nas-deploy.sh             # Deploy desde CI/CD
```

### 2. DOCKER COMPOSE OPTIMIZADO PARA NAS

```yaml
# deploy/nas/docker-compose.yml
version: '3.8'

services:
  ai-service:
    image: ghcr.io/your-org/ai-service:${VERSION:-latest}
    container_name: ai-service
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=--max-old-space-size=1024
      - DATABASE_URL=postgres://user:pass@postgres:5432/ai_service
    volumes:
      - ./data:/app/data:ro
      - ./config:/app/config:ro
    mem_limit: 2g
    memswap_limit: 2g
    cpus: 2
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      postgres:
        condition: service_healthy

  postgres:
    image: postgres:15-alpine
    container_name: ai-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=ai_service
      - POSTGRES_USER=ai_user
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_INITDB_ARGS=--encoding=UTF8
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init:/docker-entrypoint-initdb.d:ro
    mem_limit: 3g
    memswap_limit: 3g
    cpus: 1.5
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Monitoring mÃ­nimo
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    mem_limit: 128m
    cpus: 0.1

volumes:
  postgres_data:
    driver: local

networks:
  default:
    driver: bridge
```

### 3. GITHUB ACTIONS PARA BUILD EXTERNO

```yaml
# .github/workflows/build-and-test.yml
name: Build and Push

on:
  push:
    branches: [main, develop]
    tags: ['v*']

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Build and test
        run: |
          # Build test image
          docker build --target tester -t test-image .
          # Run tests
          docker run --rm test-image
          
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=semver,pattern={{version}}
            type=sha,prefix={{branch}}-
            
      - name: Build and push production image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          target: production
          
      - name: Notify NAS for deployment
        if: github.ref == 'refs/heads/main'
        run: |
          curl -X POST https://your-nas-webhook/deploy \
            -H "Authorization: Bearer ${{ secrets.NAS_DEPLOY_TOKEN }}" \
            -d '{"image":"${{ steps.meta.outputs.tags }}","version":"${{ github.sha }}"}'
```

### 4. SCRIPT DE DEPLOYMENT PARA NAS

```bash
#!/bin/bash
# scripts/nas-deploy.sh

set -euo pipefail

# ConfiguraciÃ³n
COMPOSE_FILE="/volume1/docker/ai-service/docker-compose.yml"
ENV_FILE="/volume1/docker/ai-service/.env"
BACKUP_DIR="/volume1/docker/ai-service/backups"
MAX_BACKUPS=5

# Funciones
log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
}

backup_current() {
    log "Creating backup..."
    local backup_name="backup-$(date +%Y%m%d-%H%M%S)"
    docker commit ai-service "${backup_name}"
    docker tag "${backup_name}" "ai-service:backup-latest"
    
    # Limpiar backups antiguos
    docker images --format "{{.Repository}}:{{.Tag}}" | \
        grep "^backup-" | \
        sort -r | \
        tail -n +$((MAX_BACKUPS + 1)) | \
        xargs -r docker rmi
}

health_check() {
    log "Running health check..."
    local max_attempts=30
    local attempt=0
    
    while [ $attempt -lt $max_attempts ]; do
        if curl -f http://localhost:3000/health > /dev/null 2>&1; then
            log "Health check passed"
            return 0
        fi
        attempt=$((attempt + 1))
        sleep 2
    done
    
    log "Health check failed"
    return 1
}

deploy() {
    local new_version="${1:-latest}"
    
    log "Starting deployment of version: $new_version"
    
    # Backup actual
    backup_current
    
    # Actualizar versiÃ³n
    sed -i "s/VERSION=.*/VERSION=$new_version/" "$ENV_FILE"
    
    # Pull nueva imagen
    log "Pulling new image..."
    docker-compose -f "$COMPOSE_FILE" pull ai-service
    
    # Deploy con zero-downtime
    log "Starting new container..."
    docker-compose -f "$COMPOSE_FILE" up -d --no-deps --scale ai-service=2 ai-service
    
    # Esperar health check
    if health_check; then
        log "Deployment successful, cleaning up old container..."
        docker-compose -f "$COMPOSE_FILE" up -d --no-deps --remove-orphans ai-service
    else
        log "Deployment failed, rolling back..."
        docker-compose -f "$COMPOSE_FILE" up -d --no-deps --force-recreate \
            --scale ai-service=1 ai-service
        docker tag "ai-service:backup-latest" "ai-service:current"
        exit 1
    fi
    
    log "Deployment completed successfully"
}

# Main
case "${1:-deploy}" in
    deploy)
        deploy "${2:-latest}"
        ;;
    rollback)
        log "Rolling back to previous version..."
        docker tag "ai-service:backup-latest" "ai-service:current"
        docker-compose -f "$COMPOSE_FILE" up -d --force-recreate ai-service
        ;;
    status)
        docker-compose -f "$COMPOSE_FILE" ps
        ;;
    *)
        echo "Usage: $0 {deploy|rollback|status} [version]"
        exit 1
        ;;
esac
```

### 5. MAKEFILES ADAPTADOS PARA NAS

```makefile
# Makefile.nas - Comandos especÃ­ficos para NAS

# ConfiguraciÃ³n
include .make.env
NAS_DEPLOY_SCRIPT := scripts/nas-deploy.sh

.PHONY: nas-deploy
nas-deploy: ## Deploy to NAS
	@echo "ğŸš€ Deploying to NAS..."
	@sshpass -p "$(SSHPASS)" ssh $(NAS_USER)@$(NAS_HOST) \
		"cd $(NAS_PATH) && ./deploy/nas/update.sh deploy $(VERSION)"

.PHONY: nas-rollback
nas-rollback: ## Rollback on NAS
	@echo "â®ï¸ Rolling back on NAS..."
	@sshpass -p "$(SSHPASS)" ssh $(NAS_USER)@$(NAS_HOST) \
		"cd $(NAS_PATH) && ./deploy/nas/update.sh rollback"

.PHONY: nas-status
nas-status: ## Check NAS deployment status
	@echo "ğŸ“Š NAS Status:"
	@sshpass -p "$(SSHPASS)" ssh $(NAS_USER)@$(NAS_HOST) \
		"cd $(NAS_PATH) && docker-compose ps"

.PHONY: nas-logs
nas-logs: ## View NAS logs
	@sshpass -p "$(SSHPASS)" ssh $(NAS_USER)@$(NAS_HOST) \
		"cd $(NAS_PATH) && docker-compose logs -f --tail=100"

.PHONY: nas-resources
nas-resources: ## Check NAS resource usage
	@echo "ğŸ’¾ NAS Resources:"
	@sshpass -p "$(SSHPASS)" ssh $(NAS_USER)@$(NAS_HOST) \
		"docker stats --no-stream"

.PHONY: nas-backup
nas-backup: ## Create NAS backup
	@echo "ğŸ’¼ Creating backup..."
	@sshpass -p "$(SSHPASS)" ssh $(NAS_USER)@$(NAS_HOST) \
		"cd $(NAS_PATH) && ./deploy/backup/backup-strategy.sh"
```

## ğŸ“Š RECURSOS Y LIMITACIONES

### DistribuciÃ³n de Memoria (10GB Total)

```
Sistema Synology DSM: ~1.5GB
PostgreSQL:          3GB (con buffer pool)
AI Service:          2GB (Node.js optimizado)
Monitoring:          256MB (node-exporter + logs)
Docker overhead:     512MB
Buffer/Cache:        2.7GB
```

### LÃ­mites de CPU

```
PostgreSQL:    1.5 cores
AI Service:    2 cores
Monitoring:    0.1 cores
Reserva:       0.4 cores
```

## ğŸš¨ MONITOREO LIGERO

### Script de Monitoreo BÃ¡sico

```bash
#!/bin/bash
# monitoring/lightweight/monitor.sh

# MÃ©tricas bÃ¡sicas cada minuto
while true; do
    {
        echo "# HELP system_memory_usage Memory usage in MB"
        echo "# TYPE system_memory_usage gauge"
        free -m | awk 'NR==2{printf "system_memory_usage %s\n", $3}'
        
        echo "# HELP container_health Container health status"
        echo "# TYPE container_health gauge"
        docker ps --format "table {{.Names}}\t{{.Status}}" | \
            tail -n +2 | \
            while read name status; do
                if [[ $status == *"healthy"* ]]; then
                    echo "container_health{name=\"$name\"} 1"
                else
                    echo "container_health{name=\"$name\"} 0"
                fi
            done
    } > /tmp/metrics.prom
    
    sleep 60
done
```

## ğŸ‘¥ PERSONAS Y ROLES PARA CLAUDE.md

### DefiniciÃ³n de Agentes Especializados

```markdown
## ğŸ¤– AGENTES ESPECIALIZADOS

### 1. ğŸ—ï¸ DevOps Architect (Anna)
**Personalidad**: Meticulosa, orientada a la estabilidad
**Expertise**: 
- Infraestructura en NAS limitados
- OptimizaciÃ³n de recursos
- Docker y containerizaciÃ³n

**Responsabilidades**:
- DiseÃ±ar arquitectura dentro de lÃ­mites de hardware
- Optimizar consumo de recursos
- Definir estrategias de deployment

**Frases tÃ­picas**:
- "Â¿Esto cabe en 10GB de RAM?"
- "Necesitamos externalizar este proceso"
- "El NAS no es un servidor de builds"

### 2. ğŸ”§ CI/CD Engineer (Carlos)
**Personalidad**: PragmÃ¡tico, automatizador compulsivo
**Expertise**:
- GitHub Actions
- Build optimization
- Pipeline automation

**Responsabilidades**:
- Configurar pipelines externos
- Optimizar tiempos de build
- Integrar con el NAS

**Frases tÃ­picas**:
- "Si es manual, lo automatizo"
- "Los builds van en GitHub, no en el NAS"
- "Â¿Por quÃ© tardÃ³ mÃ¡s de 5 minutos?"

### 3. ğŸ›¡ï¸ Security Guardian (Elena)
**Personalidad**: Paranoica profesional, zero-trust
**Expertise**:
- Container security
- Secrets management
- Network isolation

**Responsabilidades**:
- Escaneo de vulnerabilidades
- GestiÃ³n de secretos
- PolÃ­ticas de seguridad

**Frases tÃ­picas**:
- "Â¿EstÃ¡ este secreto en texto plano?"
- "Necesitamos escanear esa imagen"
- "El principio de menor privilegio"

### 4. ğŸ“Š Performance Monitor (Miguel)
**Personalidad**: Obsesivo con las mÃ©tricas
**Expertise**:
- Resource optimization
- Performance tuning
- Monitoring minimal

**Responsabilidades**:
- Monitorear uso de recursos
- Optimizar performance
- Alertas tempranas

**Frases tÃ­picas**:
- "Estamos al 80% de RAM"
- "Este query consume demasiado"
- "Necesitamos mÃ©tricas, no logs"

### 5. ğŸš‘ Emergency Responder (Sara)
**Personalidad**: Calmada bajo presiÃ³n
**Expertise**:
- Incident response
- Quick rollbacks
- Root cause analysis

**Responsabilidades**:
- Respuesta a incidentes
- Rollbacks rÃ¡pidos
- Post-mortems

**Frases tÃ­picas**:
- "Primero estabilizar, luego investigar"
- "Tengo un backup de hace 5 minutos"
- "Â¿CuÃ¡l fue el Ãºltimo cambio?"

## USO DE AGENTES EN CONVERSACIONES

Cuando trabajas en diferentes aspectos del proyecto, adopta la personalidad del agente correspondiente:

**Ejemplo de uso**:
```
Usuario: "Necesito configurar el CI/CD"
Claude (como Carlos): "Â¡Perfecto! Como Carlos, el CI/CD Engineer, te voy a configurar un pipeline que build en GitHub Actions y solo despliega al NAS. Recuerda: el NAS es para runtime, no para builds..."
```
```

## ğŸ“… CRONOGRAMA ADAPTADO

### Semana 1: PreparaciÃ³n
- [ ] Configurar GitHub Actions
- [ ] Crear registry en GitHub Packages
- [ ] Preparar estructura en NAS
- [ ] Backup completo actual

### Semana 2: MigraciÃ³n
- [ ] Migrar builds a GitHub
- [ ] Configurar webhook NAS
- [ ] Implementar deploy script
- [ ] Tests de integraciÃ³n

### Semana 3: OptimizaciÃ³n
- [ ] Afinar lÃ­mites de recursos
- [ ] Implementar monitoreo ligero
- [ ] Documentar procedimientos
- [ ] Training del equipo

### Semana 4: ProducciÃ³n
- [ ] Deploy final
- [ ] Monitoreo intensivo
- [ ] Ajustes finales
- [ ] DocumentaciÃ³n completa

## ğŸ¯ MÃ‰TRICAS DE Ã‰XITO AJUSTADAS

1. **Build Time**: < 5 min (en GitHub, no en NAS)
2. **Deploy Time**: < 2 min (solo pull y restart)
3. **Memory Usage**: < 8GB total
4. **CPU Usage**: < 80% sostenido
5. **Uptime**: 99.5% (considerando lÃ­mites hardware)

## âš ï¸ CONSIDERACIONES ESPECIALES NAS

### Lo que NO hacer en el NAS:
- âŒ Builds de cÃ³digo
- âŒ Tests pesados
- âŒ AnÃ¡lisis de seguridad
- âŒ CompilaciÃ³n de assets
- âŒ Procesamiento intensivo

### Lo que SÃ hacer en el NAS:
- âœ… Ejecutar contenedores
- âœ… Servir la aplicaciÃ³n
- âœ… Base de datos
- âœ… Backups locales
- âœ… Logs esenciales

## ğŸ”„ ESTRATEGIA DE BACKUP

```bash
#!/bin/bash
# deploy/backup/backup-strategy.sh

# Backup diario automÃ¡tico
BACKUP_PATH="/volume1/backup/ai-service"
RETENTION_DAYS=7

# Database backup
docker exec ai-postgres pg_dump -U ai_user ai_service | \
    gzip > "$BACKUP_PATH/db-$(date +%Y%m%d-%H%M%S).sql.gz"

# Application data
tar -czf "$BACKUP_PATH/app-data-$(date +%Y%m%d-%H%M%S).tar.gz" \
    /volume1/docker/ai-service/data

# Cleanup old backups
find "$BACKUP_PATH" -name "*.gz" -mtime +$RETENTION_DAYS -delete

# Sync to external (opcional)
# rsync -av "$BACKUP_PATH/" "backup-server:/backups/ai-service/"
```

## ğŸ“ CONCLUSIÃ“N

Este plan refinado reconoce las limitaciones del Synology DSM 420+ y las convierte en ventajas:
- Builds externalizados = NAS mÃ¡s estable
- Recursos limitados = OptimizaciÃ³n forzada
- Arquitectura simple = Menos puntos de fallo

El Ã©xito depende de respetar los lÃ­mites del hardware y usar servicios externos para tareas pesadas.

---

**Ãšltima actualizaciÃ³n**: 2025-07-09
**Hardware target**: Synology DSM 420+ (10GB RAM)
**FilosofÃ­a**: "El NAS es para servir, no para construir"